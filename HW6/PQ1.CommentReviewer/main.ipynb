{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr8tdTlLMtp2"
      },
      "source": [
        "<center>\n",
        "In God We Trust\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBWbPfcpMtp7"
      },
      "source": [
        "# CE417: Artificial Intelligence\n",
        "\n",
        "Dr. Mahdiyeh Soleymani Baghshah, Associate Professor\n",
        "\n",
        "Computer Engineering Department,\n",
        "Sharif University of Technology,\n",
        "Tehran, Tehran, Iran\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyiwK_VbMtp8"
      },
      "source": [
        "# Comment Classification (25 Points)\n",
        "\n",
        "Corresponding TA: Aryan Ahadinia\n",
        "\n",
        "In online retail stores, like digikala, people can leave comments on products and share their opinion. It's important to make sure that comment don't violet regulations so these website employ some people as comment reviewer to review comments one by and accept or reject comments. In this problem, we want to develop ML models to do comment reviewing task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j32H4FbfMtp9"
      },
      "outputs": [],
      "source": [
        "# You are denied to add any other packages.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf1mPqDTMtp_"
      },
      "source": [
        "## Data (1 Point)\n",
        "\n",
        "We want to work on data obtained from digikala. First, load train and test data separately. Then split train data into train data and validation data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_sCVwSQMtp_",
        "outputId": "cef1cfc2-d4f6-4153-f142-da19a047e4b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#############################################\n",
        "#### Load Train and Test Data, CODE HERE ####\n",
        "#############################################\n",
        "data_folder=''\n",
        "\n",
        "#Comment the below code when running local\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_folder='drive/MyDrive/'\n",
        "\n",
        "train_data=pd.read_csv(f'{data_folder}data/train.csv')[['comment','verification_status']]\n",
        "test_data_ids=pd.read_csv(f'{data_folder}data/test.csv')['id']\n",
        "test_data=pd.read_csv(f'{data_folder}data/test.csv')[['comment']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmOg0XDvMtqB"
      },
      "outputs": [],
      "source": [
        "####################################################\n",
        "#### Split into train and validation, CODE HERE ####\n",
        "####################################################\n",
        "validation_size=0.1\n",
        "validation_indices=np.random.choice(len(train_data),int(len(train_data)*validation_size),replace=False)\n",
        "validation_data=train_data.iloc[validation_indices]\n",
        "train_data=train_data.drop(validation_indices,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10RZIjjwMtqC",
        "outputId": "88c34d5b-2a9e-434c-bd79-064d981b5e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             comment  verification_status\n",
            "0                  خیلی دیر شارژ میشه. من پس فرستادم                    0\n",
            "1  اول قرار بود بخاری برقی یا فن هیتر بخریم ولی چ...                    0\n",
            "2  یک هفته پیش خریدم. یکی از دوستانم که کافی شاپ ...                    0\n",
            "3  سلام . شاید تکنولوژی ar جدید و خوب باشد اما تو...                    0\n",
            "4                       موزها تازه و قیمتم مناسب بود                    0\n",
            "train data size: (144000, 2)\n",
            "validation data size: (16000, 2)\n"
          ]
        }
      ],
      "source": [
        "###############################\n",
        "####### Show Train Data #######\n",
        "###############################\n",
        "print(train_data.head())\n",
        "print(f'train data size: {train_data.shape}')\n",
        "print(f'validation data size: {validation_data.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkJeMugyMtqE",
        "outputId": "656f02cb-9198-4243-fdb8-027a918f26dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             comment\n",
            "0  جنس تاریخ گذشته بود.حدود دو هفته می گذشت از ان...\n",
            "1  من این محصول را امروز از دیجی کالا تحویل گرفتم...\n",
            "2  اصلا خوب نیست، فقط در این حد خوبه که گوشی خامو...\n",
            "3             کلا دو بار استفاده کردم بدنه مخزن شکست\n",
            "4  فقط برای لباسشویی خوب است و در ظرفشویی بعد از ...\n",
            "test data shape: (20000, 1)\n"
          ]
        }
      ],
      "source": [
        "###############################\n",
        "####### Show Test Data ########\n",
        "###############################\n",
        "print(test_data.head())\n",
        "print(f'test data shape: {test_data.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COeWUbhvMtqF"
      },
      "source": [
        "## Data Cleaning (5 Points)\n",
        "\n",
        "One of the most important steps im ML task is data cleaning. Data cleaning, generally, aim to transform data in a known domain in which is appropriate for the task. In this section, we explore some data cleaning techniques on text data. There are several libraries for text processing in persian like `hazm` and `parsi.io`. In this section, you can use these libraries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vpy0hqmXMtqF"
      },
      "source": [
        "### Normalizations (1 Point)\n",
        "\n",
        "It is possible to have multiple form for a character or a word. For example some of characters like ک or ی in persian, has different encoding. In persian, the other problem is zero-width non joiner (ZWNJ) which may cause different written form of same words.\n",
        "\n",
        "Apply a text normalization on your data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThBO0rH_aEOt",
        "outputId": "c0bdbd69-4c2c-4bf6-efe5-5706d281272f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hazm in /usr/local/lib/python3.8/dist-packages (0.7.0)\n",
            "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.8/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from nltk==3.3->hazm) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install hazm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lywHVMXMtqG",
        "outputId": "6c85c3d6-0bd3-48b5-be27-67090493257a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:22<00:00,  7.54s/it]\n"
          ]
        }
      ],
      "source": [
        "###################################\n",
        "#### Normalizations, CODE HERE ####\n",
        "###################################\n",
        "from hazm import Normalizer\n",
        "normalizer=Normalizer()\n",
        "for data in tqdm([train_data, test_data,validation_data]):\n",
        "  data['comment']=data['comment'].apply(lambda x:normalizer.normalize(x) if type(x)==str else float('nan'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bDXtM5CMtqH"
      },
      "source": [
        "### Stemming/Lemmatisation (2 Points)\n",
        "\n",
        "In many languages, like persian, arabic, and english, many words have a same root. Stemming and Lemmatisation are methods to transform all words is a family to a single form. In stemming we aim to find a common form for all word. It is not necessary to find the root as the common form. Moreover, it is possible to find the common form as a meaningless word. In lemmatisation we aim to find the root as the common form.\n",
        "\n",
        "Apply both Stemming and Lemmatisation on data. In following cells, you can choose to use which of the outputs at your own discretion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEbKOh8QMtqH",
        "outputId": "d65bb219-1b30-4827-bf0a-c328c75af610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:24<00:00,  8.21s/it]\n"
          ]
        }
      ],
      "source": [
        "###################################\n",
        "####### Stemming, CODE HERE #######\n",
        "###################################\n",
        "from hazm import Stemmer\n",
        "from hazm import WordTokenizer\n",
        "stemmer=Stemmer()\n",
        "tokenizer=WordTokenizer()\n",
        "for data in tqdm([train_data, test_data,validation_data]):\n",
        "  data['comment']=data['comment'].apply(lambda x:' '.join([stemmer.stem(y) for y in tokenizer.tokenize(x)]) if type(x)==str else float('nan'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ab_n_5MJMtqI",
        "outputId": "4b219ee8-81ca-4532-9b1b-fbc4ca40ae2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:12<00:00,  4.10s/it]\n"
          ]
        }
      ],
      "source": [
        "###################################\n",
        "#### Lemmatisation, CODE HERE #####\n",
        "###################################\n",
        "from hazm import Lemmatizer\n",
        "lemmatizer=Lemmatizer()\n",
        "for data in tqdm([train_data, test_data,validation_data]):\n",
        "  data['comment']=data['comment'].apply(lambda x:' '.join([lemmatizer.lemmatize(y) for y in tokenizer.tokenize(x)]) if type(x)==str else float('nan'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8frL33FZMtqI"
      },
      "source": [
        "### Stop Words / Punctuations Removal (2 Points)\n",
        "\n",
        "In all languages, including Persian, there are very frequent words, including conjunctions, prepositions, and documentary verbs, which do not carry much meaning. Also, in normal natural language processing tasks, punctuation marks such as periods and commas are removed to clean the data.\n",
        "\n",
        "Remove stop words and punctuations in following cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkFaGIFyMtqJ",
        "outputId": "c1d2c678-c633-4fe1-8885-805ec811fef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:28<00:00,  9.53s/it]\n"
          ]
        }
      ],
      "source": [
        "############################################\n",
        "####### Stop Word Removal, CODE HERE #######\n",
        "############################################\n",
        "from hazm import stopwords_list\n",
        "stp_list=stopwords_list()\n",
        "for data in tqdm([train_data, test_data,validation_data]):\n",
        "  data['comment']=data['comment'].apply(lambda x:' '.join(list(filter(lambda x:x not in stp_list,tokenizer.tokenize(x)))) if type(x)==str else float('nan'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1EPCD_2MtqJ",
        "outputId": "d26b6c5b-177e-4896-8029-245de752d4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:04<00:00,  1.64s/it]\n"
          ]
        }
      ],
      "source": [
        "############################################\n",
        "###### Punctuations Removal, CODE HERE #####\n",
        "############################################\n",
        "\n",
        "punc_list=['.','،',':','!','؟',')','(']\n",
        "for data in tqdm([train_data, test_data,validation_data]):\n",
        "  data['comment']=data['comment'].apply(lambda x:' '.join(list(filter(lambda x:x not in punc_list,tokenizer.tokenize(x)))) if type(x)==str else float('nan'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tklgWGxhgIl"
      },
      "outputs": [],
      "source": [
        "X_train=train_data['comment'].apply(lambda x: tokenizer.tokenize(x) if type(x)==str else float('nan'))\n",
        "y_train=np.array(train_data['verification_status'])\n",
        "\n",
        "\n",
        "X_validation=validation_data['comment'].apply(lambda x: tokenizer.tokenize(x) if type(x)==str else float('nan'))\n",
        "y_validation=np.array(validation_data['verification_status'])\n",
        "\n",
        "X_test=test_data['comment'].apply(lambda x:tokenizer.tokenize(x) if type(x) ==str else float('nan'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu6oJIU6MtqJ"
      },
      "source": [
        "## Naive Bayes (5 Points)\n",
        "\n",
        "In this part, we want to implement a naive bayes classifier with assumption of independent distribution between features, which are tokens in our problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTRUKQj2MtqK"
      },
      "outputs": [],
      "source": [
        "class NaiveBayes:\n",
        "    def __init__(self):\n",
        "      self.words_frequency_dict=dict()\n",
        "      self.p_y=dict()\n",
        "  \n",
        "    def fit(self, X, y):\n",
        "        ##################################\n",
        "        ######### YOUR CODE HERE #########\n",
        "        ##################################\n",
        "        #X is a Series of comments and y is the verification status\n",
        "        y=np.array(y)\n",
        "        self.p_y[0]=sum(y==0)/len(y)\n",
        "        self.p_y[1]=sum(y==1)/len(y)\n",
        "        for i,comment in tqdm(enumerate(X)):\n",
        "          if type(comment)!=list:continue\n",
        "          for token in set(comment):\n",
        "            if self.words_frequency_dict.get(token) is None:\n",
        "              self.words_frequency_dict[token]={0:0,1:0}\n",
        "              self.words_frequency_dict[token][y[i]]+=1\n",
        "            self.words_frequency_dict[token][y[i]]+=1\n",
        "        def func(d:dict,l):\n",
        "          return {k:v/l for k,v in d.items()}\n",
        "        self.words_frequency_dict={k:func(v,len(X)) for k,v in self.words_frequency_dict.items()}\n",
        "    def predict(self, X):\n",
        "        ##################################\n",
        "        ######### YOUR CODE HERE #########\n",
        "        ##################################\n",
        "        y_pred=np.zeros(shape=len(X))\n",
        "        for i,comment in tqdm(enumerate(X)):\n",
        "          if type(comment)!=list:continue\n",
        "          log_prob_0=np.log(self.p_y[0])\n",
        "          log_prob_1=np.log(self.p_y[1])\n",
        "          for token in set(comment):\n",
        "            if self.words_frequency_dict.get(token) is None:continue\n",
        "            if self.words_frequency_dict[token][0]==0:\n",
        "              log_prob_0=float('-inf')\n",
        "            else:\n",
        "              log_prob_0+=np.log(self.words_frequency_dict[token][0])\n",
        "            if self.words_frequency_dict[token][1]==0:\n",
        "              log_prob_1=float('-inf')\n",
        "            else:\n",
        "              log_prob_1+=np.log(self.words_frequency_dict[token][1])\n",
        "          if log_prob_0>log_prob_1:\n",
        "            y_pred[i]=0\n",
        "          else:\n",
        "            y_pred[i]=1\n",
        "        return y_pred.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxT5Nplwvria",
        "outputId": "5df13317-0ad9-43f1-c938-d316125123c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "144000it [00:03, 44938.47it/s]\n"
          ]
        }
      ],
      "source": [
        "naive_bayes=NaiveBayes()\n",
        "naive_bayes.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqFAX02AMtqK"
      },
      "source": [
        "## TF-IDF Vectorization (3 Points)\n",
        "\n",
        "There are several methods for generating a vectorized representations for tokens. Consider our token is words. and we want to develop a vectorizer to vectorize words. The main problem in vectorization is to maintain as much information as possible. A good assumptions is that frequency of a work represent the importance of that word. The assumption has a trivial exception. Stop words such as 'is', 'and', 'are', and e.t.c are very frequent. TF-TDF leverage term frequency and inverse document frequency to solve this problem. Document frequency shows that how frequents is a token among all documents. As the document frequency increases, the importance of that token drops. In the other hand, if a word has high frequency in a documents, it is likely to that word play a key role in that document so the importance of that token increases.\n",
        "\n",
        "In this section, you have to implement a TF-IDF vectorizer. Search about this method in Google and implement it.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky3_XeqCMtqK",
        "outputId": "2f7563b7-b831-4d3d-8a8f-25868f2bc1d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 5503.61it/s]\n"
          ]
        }
      ],
      "source": [
        "class TF_IDF:\n",
        "    def __init__(self):\n",
        "      self.term_status=list()\n",
        "      self.documents_status=dict()\n",
        "      self.count_documents=0\n",
        "      self.tokens=dict()\n",
        "    def fit(self, X) -> None:\n",
        "        ##################################\n",
        "        ######### YOUR CODE HERE #########\n",
        "        ##################################\n",
        "        id=0\n",
        "        for comment in X:\n",
        "          if type(comment)!=list:continue\n",
        "          for token in set(comment):\n",
        "            if self.tokens.get(token) is None:\n",
        "              self.tokens[token]=id\n",
        "              id+=1\n",
        "\n",
        "    def transform(self, X) -> np.ndarray:\n",
        "        ##################################\n",
        "        ######### YOUR CODE HERE #########\n",
        "        ##################################\n",
        "        transformed_X=[]\n",
        "        for comment in X:\n",
        "          if type(comment)!=list:continue\n",
        "          self.count_documents+=1\n",
        "          term_status_dict=dict()\n",
        "          for token in comment:\n",
        "            term_status_dict.setdefault(token,0)\n",
        "            term_status_dict[token]+=1\n",
        "          self.term_status.append(term_status_dict)\n",
        "          for token in set(comment):\n",
        "              self.documents_status.setdefault(token,0)\n",
        "              self.documents_status[token]+=1\n",
        "        i=0\n",
        "        for comment in tqdm(X):\n",
        "          vector=np.zeros(len(self.tokens))\n",
        "          if type(comment)!=list:\n",
        "            transformed_X.append(vector)\n",
        "            continue\n",
        "          comment=np.array(comment)\n",
        "          for token in comment:\n",
        "            if self.tokens.get(token) is None:continue\n",
        "            tf=self.term_status[i][token]/len(comment)\n",
        "            idf=np.log(self.count_documents/self.documents_status[token])\n",
        "            vector[self.tokens.get(token)]=tf*idf\n",
        "          i+=1\n",
        "          transformed_X.append(vector)\n",
        "          # gc.collect()\n",
        "        transformed_X=np.array(transformed_X)\n",
        "        return transformed_X\n",
        "sample_data=X_train[:10]\n",
        "t=TF_IDF()\n",
        "t.fit(sample_data)\n",
        "res=t.transform(sample_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the size of the feature matrix is too large to store(6000 columns(different tokens) * 100000 rows(comments) we can't store this matrix in RAM and hence the following code would make the colab crash :)"
      ],
      "metadata": {
        "id": "NeVra4mlPHg4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OTsQaWAhKCA"
      },
      "outputs": [],
      "source": [
        "# The following code crashes the colab because it runs out of RAM\n",
        "# Don't run it :)\n",
        "vectorizer=TF_IDF()\n",
        "vectorizer.fit(X_train)\n",
        "vectorized_X_train=vectorizer.transform(X_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AefkJ7ntMtqL"
      },
      "source": [
        "## Logistic Regression (5 Points)\n",
        "\n",
        "In this part we want to train a logistic regression classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXX3QZTVIKcV"
      },
      "source": [
        "$Loss=-∑_{i=0}^{n}y^i\\times log(sigmoid(y_{prediction}))+(1-y^i)log(1-sigmoid(y_{prediction}))$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rbVc3POMtqL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "class LogisticRegression:\n",
        "    def __init__(self,learning_rate,iterations):\n",
        "      self.learning_rate=learning_rate\n",
        "      self.iterations=iterations\n",
        "    def _loss(self, X, y) -> float:\n",
        "        ##########################################################\n",
        "        ######### Calculate the loss function. CODE HERE #########\n",
        "        ######### You can use logarithm to avoid underflow #######\n",
        "        ##########################################################\n",
        "        pred=np.dot(X,self.W)+self.b\n",
        "        loss=0\n",
        "        for i in range(len(y)):\n",
        "          if y[i]==1:\n",
        "            loss-=np.log(1/(1+np.exp(-pred[i])))\n",
        "          else:\n",
        "            loss-=np.log(1-1/(1+np.exp(-pred[i])))\n",
        "        return loss\n",
        "\n",
        "    def _gradient(self, X, y) -> np.ndarray:\n",
        "        ##########################################################\n",
        "        ######### Calculate the gradient. CODE HERE ##############\n",
        "        ##########################################################\n",
        "        pred=np.dot(X,self.W)+self.b\n",
        "        s = 1 /( 1+np.exp(-pred))\n",
        "        tmp = ( s - y.reshape(-1,1) )       \n",
        "        dW = np.dot( X.T, tmp )  \n",
        "        db=sum(tmp)[0]\n",
        "        return dW,db\n",
        "\n",
        "    def fit(self, X, y) -> None:\n",
        "        ##########################################################\n",
        "        ######### Train the model. CODE HERE #####################\n",
        "        ##########################################################\n",
        "        self.W=np.random.random(size=(X.shape[1],1))\n",
        "        self.b=0\n",
        "        train_losses=[]\n",
        "        for it in range(self.iterations):\n",
        "            grad_W,grad_b=self._gradient(X,y)\n",
        "            self.W-=grad_W*self.learning_rate\n",
        "            self.b-=grad_b*self.learning_rate\n",
        "            train_losses.append(self._loss(X,y))\n",
        "        print(f'train_losses:\\n',train_losses)\n",
        "        \n",
        "\n",
        "    def predict(self, X) -> np.ndarray:\n",
        "        ##########################################################\n",
        "        ######### Predict the result. CODE HERE ##################\n",
        "        ##########################################################\n",
        "        z=np.dot(X,self.W)+self.b\n",
        "        y = np.where( z > 0.5, 1, 0 )  \n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We test the logistic regression to make sure it works\n",
        "lg=LogisticRegression(0.1,10)\n",
        "X=np.array([[1,2,1,0],[3,5,1,2]])\n",
        "y=np.array([0,1])\n",
        "lg.fit(X,y)\n",
        "\n",
        "print(lg.predict([[1,2,1,0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65onwtqNRsH0",
        "outputId": "e0c8127c-0e09-43c7-a772-423b5edc66c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.63965571]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.06895299])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAzB1AvkMtqL"
      },
      "source": [
        "## Evaluation (3 Points)\n",
        "\n",
        "Now we want to evaluate our models on validation data. Calculate following metrics for both models.\n",
        "\n",
        "Note that since our task is to find the comments which violet regulations, we take the positive class to be identified as a not verified comment.\n",
        "<br>\n",
        "True Positive (TP)= comments correctly classified as not verified (0)\n",
        "<br>\n",
        "False Positive (FP)= comments wrongly classified as not verified (0)\n",
        "<br>\n",
        "False Negative (FN)= comments wrongly classified as verified (1)\n",
        "<br>\n",
        "$Precision=\\frac{TP}{TP+FP}$\n",
        "$Recall=\\frac{TP}{TP+FN}$\n",
        "$F1\\_score=2*\\frac{(Precision*Recall)}{Precision+Recall}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zViProG1MtqM"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_real, y_predicted) -> float:\n",
        "    ##########################################################\n",
        "    ######### Calculate the accuracy. CODE HERE ##############\n",
        "    ##########################################################\n",
        "    return sum(y_real==y_predicted)/len(y_real)\n",
        "\n",
        "\n",
        "def precision(y_real, y_predicted) -> float:\n",
        "    ##########################################################\n",
        "    ######### Calculate the precision. CODE HERE #############\n",
        "    ##########################################################\n",
        "    TP=sum((y_real==y_predicted) & (y_predicted==0))\n",
        "    FP=sum((y_real !=y_predicted) & (y_predicted==0))\n",
        "    return TP/(TP+FP)\n",
        "\n",
        "def recall(y_real, y_predicted) -> float:\n",
        "    ##########################################################\n",
        "    ######### Calculate the recall. CODE HERE ################\n",
        "    ##########################################################\n",
        "    TP=sum((y_real==y_predicted) & (y_predicted==0))\n",
        "    FN=sum((y_real !=y_predicted) & (y_predicted==1))\n",
        "    return TP/(TP+FN)\n",
        "\n",
        "\n",
        "def f1_score(y_real, y_predicted) -> float:\n",
        "    ##########################################################\n",
        "    ######### Calculate the f1_score. CODE HERE ##############\n",
        "    ##########################################################\n",
        "    p=precision(y_real,y_predicted)\n",
        "    r=recall(y_real,y_predicted)\n",
        "    return 2*p*r/(p+r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCi4MfTEMtqM",
        "outputId": "16868caa-3315-43db-b897-32499969d272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "16000it [00:02, 5957.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes:\n",
            "Accuracy: 0.87325, Precision: 0.8808402291534054, Recall: 0.988852365299414, F1-score: 0.9317263668192836\n"
          ]
        }
      ],
      "source": [
        "############################################\n",
        "######### Metrics for Naive Bayes ##########\n",
        "############################################\n",
        "y_pred=naive_bayes.predict(X_validation)\n",
        "print(f'Naive Bayes:\\nAccuracy: {accuracy(y_validation,y_pred)}, Precision: {precision(y_validation,y_pred)}, Recall: {recall(y_validation,y_pred)}, F1-score: {f1_score(y_validation,y_pred)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zABt-gMHMtqM"
      },
      "outputs": [],
      "source": [
        "############################################\n",
        "######### Metrics for Logistic Regression ##\n",
        "############################################\n",
        "\n",
        "# Because we couldn't store feature matrix in RAM we couldn't test Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkfTbSAtMtqN"
      },
      "source": [
        "## Evaluation on Test data (3 Points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXgb_u7VMtqN"
      },
      "source": [
        "At the final point, you have to run your model on test data and create a csv file with two columns: `id` and `verification_status`. Then run the `CommentJudge.jar` with following command and report your metrics. you must take an screenshot and import that in the notebook.\n",
        "\n",
        "```bash\n",
        "java -jar CommentJudge.jar ans.csv\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we couldn't use logistic regression we use Naive bayes for this part"
      ],
      "metadata": {
        "id": "FHynh21Njbfo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5aVmnkpMtqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "494c6e42-43d7-49eb-bb53-3b0c0006dc9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20000it [00:01, 16125.76it/s]\n"
          ]
        }
      ],
      "source": [
        "###################################\n",
        "############ Code Here ############\n",
        "###################################\n",
        "res=naive_bayes.predict(X_test)\n",
        "ids=[]\n",
        "verification_status=[]\n",
        "for i in range(len(res)):\n",
        "  ids.append(test_data_ids[i])\n",
        "  verification_status.append(res[i])\n",
        "df=pd.DataFrame({'id':ids,'verification_status':verification_status})\n",
        "df.to_csv('ans.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Judge score.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAeAB4AAD/4RCIRXhpZgAATU0AKgAAAAgABAE7AAIAAAAHAAAISodpAAQAAAABAAAIUpydAAEAAAAOAAAQcuocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFBhcmhhbQAAAAHqHAAHAAAIDAAACGQAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFAAYQByAGgAYQBtAAAA/+EKX2h0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPlBhcmhhbTwvcmRmOmxpPjwvcmRmOlNlcT4NCgkJCTwvZGM6Y3JlYXRvcj48L3JkZjpEZXNjcmlwdGlvbj48L3JkZjpSREY+PC94OnhtcG1ldGE+DQogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgIDw/eHBhY2tldCBlbmQ9J3cnPz7/2wBDAAcFBQYFBAcGBQYIBwcIChELCgkJChUPEAwRGBUaGRgVGBcbHichGx0lHRcYIi4iJSgpKywrGiAvMy8qMicqKyr/2wBDAQcICAoJChQLCxQqHBgcKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKir/wAARCAA6A/YDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD56oror7wdNpdmranq2m2l+1uLgaZLJJ9oCEbgGIQxqxXkKzhuQMZIFc7R1sAUVsNoBbwamv285lVbw2lzD5eDASu5Gzk5DDcOgwV71HLoF1D4Vt9faSE2txdPaIgY7w6KrEkYxjDDvRtfy/X/AIcP6/r7jLorU1/Qbrw5qMdnfSQySSW8VwDCxI2yIHUcgc4IzWXQAUUUUAFFFbHiHQDocli8c5urTULOO7t5/L2bgwwykZPKsGU8np70AY9FdlD8Nr24bT7eLWNJOpalZLe2mnF5lllRlJVQxj8vcdpGC/WuPZWRyrqVZTggjBBo2dg6XG0UVtaZ4e/tHwrres/afL/skwfufLz5vmuV+9njGM9Dn2oAxaKKKACinxhDKglZkjLDcyruIHcgZGfpkVq+IvD0vh/xPNpDTLOFZTDcBSqzRuAyOBzgFSD3p2baQGPRXYap8OL7TrjU7W31fStRv9KVnvLK1eUSxooyzDzI0Vwo67ST7Vx9TdMAoorYj0Lf4Lm1/wC048q/Sz8jy+u6Nn3bs/7OMY79afS4dbGPRWp4e0C68Sar/Z9jJDHL5Ms26ZiF2xoXPQHnCnHvWXQAUUU+MIZUErMkZYbmVdxA7kDIz9MijcBlFa3ibQZPDXiG50ySUXCxlWhnVdomjYBkcD0KkHvVubwZqUHgmLxO725tJHC+SGbzlUsyiQjGNpZGGc5z2o6XDqc9RRWpa6BdXfhm/wBcjkhFtYTRQyozHeWk3bcDGMfKc5Io6XAy6K0tCstMv9RMOt6sdJthEzC4Fs0+WA+VdqkHk8Z6CneG9Dm8S+I7LSLaRIpLuTZ5kn3UGMlj9ACaOthX0uZdFal/a6LHqUMOl6pd3FszbZri6sVh2c4yFWR9wxz1B9qh1m1sLLWLi30fUTqdlGwEV4YGh80YHOxiSvORz6UDKNFFaWpWWmW2nadNp2rG+ubiItd2/wBmaP7I2eF3E4fI5yOKAM2iiuktPDWn3/gfU9ctdTuftWmeT9otJLNVjPmOVG2QSEnGM8oP60dLgc3RRW/4Y8K/8JRLLDBrOnWNxGjyeTdifcyIhdmBSJhgAHgkHjgUAYFFWL23jtbySGC8hvY0Py3EAcI/HYOqt7cgVPomkz69rtlpNm8aT3s6wRtKSFDMcAkgE4/A00m3ZA9NyhRU13bvZ3k1tKVLwyNGxXoSDg4/Ko12lxvJC55IGSB9KlNNXQPTcbRXR+I/DdjpOh6Nq2l6lcXttqomKi5tFgePy3CnIWRwck+tLf8AhrT4/A0HiPTdTubgNeiylt7izWHY/l7yVYSNuHbkA+wp9L/12DrY5uitK3stMk8PXd5Pqxh1KKVFg0/7Mzeep+83mZwuPQ8ms2gAooooAKKKKACinxhDKglZkjLDcyruIHcgZGfpkVq+IvD0vh/xPNpDTLOFZTDcBSqzRuAyOBzgFSD3p2baQGPRXSnwNqY8Yaj4b8+0+2afHNJK+9vLYRIXbadueg4yBz6VVv8Awre6f4sh8PSSwSXczwIjxljHmVVZeSoPRxnj1pLW1uoPS/kYlFWdRspNM1S6sJnR5LWZ4XaM5VirEEg+nFX9P0A6l4Z1TVLecmbTGiaW28vrC5K+YGz/AAttBGP4gc0k01dDtZ2MeitS10C6u/DN/rkckItrCaKGVGY7y0m7bgYxj5TnJFaUvgXUofC/9vPcWn2Y2aXgjDv5mxpjCBjbjO4Z69Pyp7f15X/IW/8AXyOZorasPCupanpEF/YIk/2nUF06G3UnzHlK7uBjGMd88ZpmqaLbaVLFG+uWF7J5myeOxEsjQY6/MyKj9x8jsDjrjmjrYDIorW8TaDJ4b8RXOlySidYyrQzhdomjYBkcD0KkHvW7qHw0v7K41Czg1fS77UtNt/tNxp9s0wlEe0MSpeJUbCsCQrE4zwaOlw62OMorq7L4faheJZRG/wBOt9R1GHz7LTJ5HE9whBKkEIUUtg7Q7qTx6jMGmeBtW1PRrzUt1taw2trLdBLmTbJOkRw5RACeDxk4XIIzkEUPTcNzm6KK1tC8PXWvPctFNb2lpZxeddXl05WKBegyQCSSeAqgsT0HWgDJoq7qdhHp9yscGoWmoROm5Z7QvtPJGCHVWU5HQqPUZBBqlQAUUUUAFFFFABRWpa6BdXfhm/1yOSEW1hNFDKjMd5aTdtwMYx8pzkir2j+EH1Xw/JrNxrGm6ZZpdrZhrzziWkK7gAI43wMZ5OKdtbf1/WoHO0Voa5ot74d1y70nVEEd1aSGOQK2Qe4IPcEEEexrPqU7q6DYKKK0tbstMsbyKPRdWOqwtAjyTfZmg2SH7yYY5OP73Q0wM2iiigAooooAKKmS0uXs5LtLeVraJlSSYISiM2cAt0BODgd8Go0CtIodtqkgFsZwPWjrYBtFaGt2mnWGsT2+jap/atkmPLvPs7QeZkAn5G5GDkfhWfQAUUUUAFFFFABRWjodnpt/q0dvrWq/2TZsrF7v7O0+wgEgbF5OTge2azzwTg5HrQAlFFFABRVvTNMvNZ1S307TIGuLu5cJFGuBuJ9zwB3JPAHJq7rOgw6Sp8nXdL1Nkk8qVLJ5CYzzzl0UOOD8yFh055GQDHooooAKKKKACiitTw9oF14k1X+z7GSGOXyZZt0zELtjQuegPOFOPegDLoq1p9rDe3iw3N/b6fGQSZ7lZCi+xEaM3P0rQ8R+GpvDjWBkvrS+h1C1F3bzWnmbWQsy8iRFYHKntRsG5i0UVsaboX9oeG9a1b7R5f8AZYgPleXnzfMk2dc8Y69DmgDHooooAKKKtabBa3OqW0GoXn2G1kkVZrnyjJ5Kk8ttHLY64FC1DYq0VYv4be31G4hsbr7XbRyssVx5Zj81QeG2nlcjnB6VXo3DYKKKKACiiigAooooAKKKKACiiigAooooAKKKKAPQviRoGp6t4u1TxLpVpNeaFej7ZDqUS5gEe37rSfdVgQV2kg5GMZIrAsf+El/4V9qn2L/kXftUX23/AFf+u/g6/P8Alx61zlFJJJcq2/r+vXUd7u7Ou8ASLfX194YuGVYdetzbxlyAEuVO+Buf9sbfo5rSt9J1DXfhLBpmjWNxfahp2tytdWdtGZJo1eJQrFFyduUYZxjIxXBwTSW1xHPbu0csTB0dTgqwOQR+NS6jqFzqupXF/fuJLm5kaWVwiruYnJOFAA59BTeqt/WjTX9eglo7/wBbWZ63Jqk8PxNvY9I0rU9YMOk2un3NzoJJubJljjWR4nVWAIKsnbPIyKh0nS1sfidfpf6jfa3q02jGex+1TCC+S5KrtiJbzNk6puA6kHbjB6eQ0Ua79dfxv/ncForen4W/yPY7XUb+9+I/ga31rw5rWnXVvfEC812YzXF2hcEKXMUZYIScZzjdiuF1TxrrWuW76TfrFfQ/bUmtYTGf9H2gqIoVUgIhBAKAdhXLUUL+vw/yDv8A13/zPVviDHqWseF59Y1I+ItASGeMLoGr7hasxLAfZM7eEUcrs+UH7x78zaZ8QfDG6tDhrvw7P9qh6bmtZSFkA9lk2N/wM1x9XdM1a90eeWbTp/JeaB7eT5QweNxhlIIIII/x6ilbR/1/Wv4D6r+v60PSPEHiLT/DN34S1OPS5rnWbbw/avazSXYFvG2GCs0Qj3MQcn74Gcccc3/h9aajZ6HoOp2U2t3kWoajI16NNvUtba0COo/0pjGwk3DnDlRg4HWvG6Ku/vOXn+tybaJf1tY9Sm1K58MeF/Gb6Cy2MieJUt4ZYVCvbptuB+7bqhwNuVwcEjvRovjHVbrwh4419GittTaPT42uIEwxYOUMuTnEhHJYYOTkYNeW0VCX6fgl/kU3+v4u57BHY3GueMtHvzeXY1L/AIRVL5mtCPtl9Mqsu2NyGIlIA+fBYBSRk10EDTpqfh6+vrW8j1EaPqwlXV7lLu5+SMsizNsXONx+VlyAcGvn+im9b28/xv8A5iXS/l+Fv8j2v4gX9zfeA9SS7kMoS20W4y/JaWSGTfIT1LsAAW6kADtXFXedf8EaJq4w11o1wul3eMZMRJeBz7D50z/siuJq7Z6te2Fje2dpPst7+NY7mMqGEiqwYdRwQRkEYP5mmnaTl53/AK+WgnqkvK39fmewalp934d+MfiXxVrlrNZaPCtyI5riPYt28kLIkcW7/WEk5+XOACTgU+xvbjStC8Pz+HvDOu67o7aWou7fTbzNjNKVInW4hWB8vknJZs424xgY8PoqErR5fRfn/mV1v/XT/I9U+HjarfeGxpNhZeJdHgnvGddf0RW8sE7V23H3Q0aDcc+YNuScGrHgcaHp3ha9h16W3uYI/EKxW13IPMthMIZBHLIvBePOCRkcHJyMg+R0Vd/0/C3+Qv8Ag/jf/M9c8Jan4w0r4v3OmeJdXv4r68iuFZGu2VLiUwuISuCFIJ27McDgDHSqHh1PE765qp8R/wBrf8JUukOdFGqeZ55beM+V5nzb9vmbdvOc45rzKip/yt+f+Yf8P+X+R7l4Xa/fxF4Lj8WRzy+J/Pvdy3ylrk2vkny1lDfMcvv2hucZxxiuV8TS60/w1kHjwXMWrtqqvpsN8hjmjh8thKEQ4KQ52AAALkcdK4vw7r114Z1631awjhkuLfdtWZSVO5SpyAQejHvWXTev9ef9X+YLR/15/wCZ2t9by+KvAui31uvmX+mTrpFwAMs0bktbsQP+Bp/wEV3TL4fv/GWpeDLTUb6SWTSv7Egt3skWBZoBvVxL5uTmVGP3Or/jXjtnq17YWN7Z2k+y3v41juYyoYSKrBh1HBBGQRg/mapUPW/n+qt/m/n5AtNf63v/AJfd5np+q+Mda8JaN4Mj0t0hRdM8y5gZMLdf6RMvlzYwXQDI2k4G5u5p3g/XPFGofDXxBp/h3UdVk1C2uLWS1s7G4lMkUGXD+UincEyVzt9s15dRQ9b36/53/wCAG1rdP8rHqfwlTxe3xGbcutm3aaZdVyJthl8t8Cftu3H+LnNUPhidW8O/E2x0q/05bSWVmaWK+05POT90xGDIm9M/7JGfevO6KAOh0/UvEur+Iorjw9FMmqJGVQaFZrbuE7nbbqvrycdOtegeKNIWD9oSK88XWb2+j3VzFi41CFlt5mWBeCzcMu/Abt1zXj1FPqvIW6Z2XixfH3mqni5NVH+l4tlulYL5nPFuDxt/65/L93/Zrf8AH2l+K7v4c+Fb3X7HWJri1W7+2XF7DKzQgyrs8xmGVyOmfwry6il0Kvrc93utKutO0PX9Ju/7Yv8AS4dAZ7a8urtF06dxEkitbW/lgZUjO5XJGCT96uQ8J+GNfufhV4rNtoepTC9Fk1qY7SRvtAWYlimB8wA64zivN6KHq2/63uJaK39dBzKyOVdSrKcEEYINd18KNF1S+8RXF3ZabeXNslheRNNDAzortbuFUsBjJJGB1ORXB0UdGu6/MOtz0XwrJqvhbwL44PlT6bqdv9hUebEUmgLSMMgMMo2DwRgjORWuniG8074meCNRl1We1/tHT7BtTuPPKfaRvKkzHPzcKMls9Oa8joqlKzT7NflYTV013X+R6vbR68fi9p0fxFGpvYfbLgWQ1iRxCz4OzY0gK7d3l8gEdMgiqXju91q48OwaZrXhfxLFcf2hut9R126a5kyVKmGN/JTKsQGwCRlcgV5rRWaVoqPYpu8nL+up6P4v8M67afC3wk11ouowCyW8N0ZLR18gNMu3fkfLntnGac/hbxAvwNCNoWphhrZuips5MiH7N/rOn3P9rpXm1FU9U13/AM7iW6f9bWPUvDemeLtU+DniOzNlrd5aOLNtNgMUskbDziXMK4Ix3O38a2vBT6jpPgrw1e6PB4kLW97czXlvoFl5yXbK6gRXJDgocDHKsNrcDOa8Trp7XxvJHpOm2GpaJpeqppZb7HJd+erRBm3Ff3cqKw3c/MCefSqvrclrSx3Ph+9v73w9rmo2Vjr9z4jk1ljfRaTqBhv4oNvyKxMUjtGH3AjA5C56DDX8QXsWmfEPV7XSpvDuoE6fmCRcTQSFtrSZ2LtdsltwVSC2R615dq+q3euaxdanqUglurqQyyuFCgsfYcCqVQtvkv0/yLfX+utz2GEx3/jXRb27e3m1q68KpNZyXgVvtF/tZYmYtwz8DBbOWC96x/D663J8SNBX4mLfMpeX7OutsVctsOwEygkJ5m3GQVzu4PzV5tRVfav6/m3+v4E/Zt/WyR6R4+1HV38MRWGv+GvEdvKl95kWp6/dm4dfkIaGNzCnynAbAJHy5ArNu86/4I0TVxhrrRrhdLu8YyYiS8Dn2Hzpn/ZFcTV2z1a9sLG9s7SfZb38ax3MZUMJFVgw6jggjIIwfzNEXyu/o/u/4GnzHLX+v69T2efU7ST40+KrNNDsIp1s78G+R7jzmxbt1BlMfPsn0xWjaaJZ6l4n0AzW0Muqatb6dqVtO7DesVskAcA5yAymckdSYxXz1RSj7qVulvwv+r/DzE9b+d/xt/l/Vj1/whc6tq1ld2FjaeJtKgvNTlmXxDoqv5e5mUYuPu7kQbjnzF25Jwa4rwpfW2g+Ontb65juNMuml068mQ5SSGTKGQE9hw4P+yK5WilFJW9LevT8im73t3v6dT03TrU+FfAfjSw1bTbbUHs9VtIHguWlVGI80bsxure45xzXYabbweJPD9hp/wBmhsbS68MCaWCB3CRxx6gGcgyMx4UMeST6V4fqmrXutX32zVJ/tFx5aRmQqAWVFCrnAGTgAZPJ71Sp6/P/AO1t/wAH8BaXv/W6f6W/E98spdLsp/C+oJb2lhp+v6hdXVtCDthid7JItmARtAmZh1BA9K4TxNYXMPgEzeLdHt9I1tdSEdlHHp8dlJLBsPmFkRVDoG2Ycg8kgE8159RSav8A122/yGnt/Xf/ADOx1XOv/DvStXGGutGk/su7xjJiOXgc+w+dM/7IrpfiF4lstA+IGvnTNMnGr3Nstq97Pdh40SSBAxSIRghtpxkuwGScdMebWerXthY3tnaT7Le/jWO5jKhhIqsGHUcEEZBGD+ZqlTet/wCt9/68xLp5f0j2STSLzVfiZ4b8XWSn/hH0t7K6m1Bf9RaLBGolR36KwMZG04JyOOazPBel6trd/wCM9Y0/Rr+Sy1LS78W0kds7LI7OCI1YDBbtgEniuH0XxJLo9neWMljaalYXuxprS8D7N6HKuDGysGGSOGwQxBBrMu7g3l7PcmKKEzSM/lwpsRMnOFXsB2FD1/H8QWiXlb8DU0nwhr2ua3caRp2mytqFsjyTW8pELRhfvbt5GCMjjrXQeEIv7Y+HviXw/py+ZrFxLbXUFsv+suo4t+9EH8TANu2jkgHA4rhaKOln/Wt/8g63PQPBWi6jpGqaxbz2k1n4l/sp5NJt5l2TiXcMlUPzLL5YcqOG7jsa7Tw9cX8X9kv4sSV/FEVjqjn+0F3XH2UQExiYP8xG/ftD9s9sV4XRQ7tNeVvz/wA/uBWTv53/AC/r1PpWwvri/wBX06O8k85Vm0G4+cZLSyRyb5Ce7MAASeSAB2rD1fVLq/8AA08d24eOfw7dyyrtADGO/VY/wQZCjooJxivBqKJa382/xVvwCOjT9Pw/zPcPFd9Pp1rqkOl+GNd1PwxPpvl2skd75ulxRmMFZljWDCOjDcTv3bg2TyaSz1e+/wCEv8D6Gtwy6Xd+HohdWq8JchoZAfMH8fAGN2cdsV4hRQ9Vb+uv+YLT+vT/ACPUPBeteKb34Y69pvh7U9Xm1C1ntHtbWyuJTLHDlw/lqpyFyVzt45Gal0LUYdM+H9xP4z0o6n/xVUYvor95VlVvKO9jhgS454bIPORXlVFO+rfp+Fv8hW0t6/in/me2QWV3aeLfG7yPf6xr7iC40+fTblba7uLVjkvAwjbnZ5YIRfu7gOMisz+33uviFb6Z4g0S+0RNY0saTenVX3TzliRFcyMY0ywYJ823+DrXk1FSkrJdP6X5fjqNt6vr/wAN/kd/4i/tXRf+Ee8HaILpdV03N1Ollu837ZLhsDZyWRAi8cg7q2/G+lai3irwXqXi+x1D+zzYWEOpXd5FIBu3t5iu7D72M5BOa8loqk2rN97iaWqXax7T4s1vVtHj1JL7wvr8til9DNaX99efaLK02Shka2xAqorL8oCtjDAc4rUPh3SdN8eajqkCEappst3rNzJ5uQbWRJjEAucAqRG3HP70Z6V4FRU29239dP8AJfkVfX+v66v8z3CyvrjS9D8P3Hh7w1r2vaQ2mL9rt9Ovc2M8pUidbiFYHy+SclmzjbjGBjk4/E2qeHPhVoMuhXDWM02qXhaaLiTaogOzeOdhOMrnBwM9K87oqru7ff8AzuJbJdv8rHeeE7/Ur7xNqniBptP0nR5JN2rCaEvZsrknyfJzmQnB2oDkYzlcZGFc+IjpfiG+ufAtzqmh2M7kRxpeMsmzPAZlIyO4BJx0y3U4FaWk6rDprSfadIsNUjcqQl4JBsIzgho3Ru5yM4PGRwMJJaeQa6+Z6lqenzat8dNXliu7tLq20xbqNLMj7VcuttH+7hYhtshyTuAJGCQM0uv63J4dv/BGtaraXyz4urfUItUu1urp4CwBjlcIpzskbCsuVyBXlGsavd67rFzqeour3Nw25yqhQOMAADoAAAB6CqNCe2ny+/8AzsDWjR6dr2kJ4XtbLwSl7FA2r6v9quLt8Mgtg5jt2bsVI3yYPYrW74xtLyHwL4rtdWg1wrY3UAspdavUkD7Zthkt4fLUxIVbHykrggZ4rxSilbS39dLfkO+t/wCut/zCtW1uPD6aYUvdM1KW+w2J4tRjjiz/AAnyzAx44yN/PtWVRTEehfCDX9Yg8faPpUOrX0enSSyF7NLlxC2Y2Jymdp5HpVnwHp+oR+FdQ1bRpdbuLg6gls9poV0trLGmwt5ss2xyI88YIC5BJPFcno/iyXQ7dTY6Xpw1CNHSHUmSTz4g2QcAOIycMwDMhYZ68DGBTvqB7Pql4dD8W/Ee+0lIIpY7C2miYKkgSR5ICZFwNu7cxYMB15FeX6/4k1DxK9nLq7LPc2tuIDdNuMs4DEgyMSdzDOM+gFZFFTbRLt/wf8w7+f8AwP8AI6/4YX9lp3jy2fUp47WKaCe3S4lbasLyRMisT2GW69s0ul+EbvQPGGlHx1pc+naV/aMcU73abEkXd820n76YHLLkAEc8iuPoqk7NS7f53E1dNdz2OVvEUdv4iT4gC7+wmeIaSt2D5YuPPGz7LnjYI9+fL+XbjPau11HU7qXVbq2dl8mTV9YtGQIAPJWzLeXj+6W+Yju3J5r5noqWrx5fK35a+ulvQpO0ub+uv+d/U+lbbVry3uLWKCQRpFdeH449qgbRLHiQj/aZflJ6leOlczpk1xpnh+wufCWj65qEkWpXR1GLQbwRZkWY7EuIxDIWQxgBQcLjcMcnPiFFU3eV/wCun+RKVopen6/5nqVz4gvtK+Gep3uhwyeH5p/FMiiGA7JbRTFuMSvgMuMAHGMgY6cVtWGr3un/AB91OwsdQms4dQhdjbxTmKOa5e0ypKggFzI3B9TxXidFLv6W/BL9Ljf9ffc6XVNK8a6zrsVprtrrV3qxgLQwagJWuHjBJ+RX+Zh944XPQ+hrvtNnjsPiX4B0+9dbe6stIFrcxSEAwzOJisbf3W/eJwcEZ5rxyijpb+uq/UOrf9dP8j1PTfD7aL4I0e18aWrWFvP4pha4guDsdIfLKlnU8qpweuMgZHHNaGvp4qTwT44Hiee5jtBc26WFpPKVRYxcY3QxZwIsbQGUBT0BODjxynI7RyK6HDKQQfQ0bu7/AK2X6fiGy0/rVv8AU948Uanrfh6y1v8AseDxU9hNpcVtBFb2jR6ZZr5aFpoplc5GATwq/eO49c1bG9uNK0Lw/P4e8M67rujtpai7t9NvM2M0pUidbiFYHy+SclmzjbjGBjgbn4k31xqF3qiaPpUGsXkLQzanGsxlIZdjMFaUxglcjIQYycYrjaTu7/1309NQWiX9dv8AI1tL8N6rrtlqd9pNmZrXTIvPu38xV8lOefmIJ6HgZPFX/A+v6xpXibTbXTNWvrK3uL6ETQ29y8aS/OB8wBAPHHNc1W1oXiMaEUkXR9NvbiGXzre4ukkLwPxgjY6huQDhwwBHTk5uLUZJkyTkmj0Cw066n8d+PdR02XVHvLG7fy7LRZBHeXAe4IJSTY7Kq9W2qc5APFat2/2P4l2961sGuT4RnmnW8kju2klWCUHzXACyt8gDEjnHNeK3VzNe3c11dSGSeeRpJHPVmJyT+ZqKs4pqCj5fo1+tzRtObl53/FP9PxNzXPF+reJNPtbfXJ/tstrJI8d3MS0xD4yhYn7gIyBjjJrP0i1W+1uxtJLiO1Se4jjaeUApECwG5geCBnNU6KuNk7kO7Vj2zxhaXkPgfxVa6tBrhWxuoBZS61epIH2zbDJbw+WpiQq2PlJXBAzxTvEur317458baLcXDNpcOhSSJZDiISLFE4k29C+7nf8Ae7ZxXiNFTbRp+f5WK6prp/met+HotV1rwDbaUY/EXhe0htZm/tO3Vl0y8Q72Zrj7uCRtTfufPA215zpPhrVtc0/Ur3S7Qz2+lw+feSeYq+UnPOGIJ6HgZNZVFN6tsS0SR6D4Oj1L/hANUk8F+a3iX7bEJRZAm8Wz2nmLb8+3zCu7b/s54p3g+88Q2fjLVDfaJrmpajNbiG8n0wML+y3FcyBgrbZMAqd2CSSCQc155RTvrf8ArawraWPUogdH+J0mj63rN1qcHiKwW0vJdR4uLczKPLWYFm2yRsEPXgDt0rA8btJomk6P4OPySabG1zfoD1upsEg+pVNi+x3VxlFTbS39eS/H8ir63CiiimIKKKKAPT/FunG60e5vPBdjoeoeForeM5tYIvtll23TnAnDbgxySUI9unLv4Y03TtIsLnxBrMtndalB9otra2s/PCRElVeVi67AxBOFDnAzjoKltPFelaNbX7+HtEubW/v7WS0kluNQE0UUcgw4jjEanpwNztgep5ps/irTNV0nToPEOizXd7plv9lt7m2vRAskQOUWVDGxbaSRlWQkHHUZpPrb+t/+AC6X/rb/AIItj4T01NN0q68R6zNprawx+yJDY+eFjD7PMkJkTapYHG0McKTjpmyvw/jsbTW7jxLrC6cNFvlsp44bczvMzK5HlDcoJ+ToxUYJOeMGvaeLtOl0nSbXxDosuoS6OWFpJBe+QGjL7/LlXy23AMTypQ4YjPQ1X1Lxldavo+r2uoQiS51TU01GS4V8BSqyLsC46fvOOeAMU5dbf1qvxte4Lpf+tH+trfialh8OTqmqakNLv59V0zT4YZTcaXZfaZ5PNAKIIVfhhzuBcBdrcngHJ8ZeEbjwhqdrbzvM8d5apdQ/aLcwTKrEgrJGSdjBlIIyR0IPNM8PeIrfStP1PS9U086hpupInmxxz+TIjoSUdH2sARkjlSCCazNSk06W6DaPa3Vrb7QDHdXKzvu7ncsaDHTjH40PyBdb/wBbFOtLW7LTbG8jj0bVv7VhaFHeb7M0OxyPmTa3Jx69DWbWlrd7pt9eRyaNpP8AZUKwojw/aWm3uB8z7m5GfToKA6mbXpmtxrr2k3TeDLjw7PZWemwyXVjFpUcV5EFjUTSeY8ClsOCSVkJwa8zrp7bxPp2j6VeweHdKuLa91C2NpcXd5eLPtib74jVYk2lsAZJbAyBzzQ/ha/r+u4L4k/66fibnw/kXXLh9P1HRdMHh+ysJn1G5FknmRgIxWU3DZkVy+0AKwHGAuM155XbJ4z0I+CbXw3JoOowwI/nXb2eqpF9tl7O+63c4HZc4HueawNN1DRrW01SO/wBEa/luYtllM140Zs25+chRiQ8jg4HHvQ/iv/X9dgW39f16/wBXu+D7rVbnVrTQtIg02SS+uAoa70u2uSpOATukjZgoAzgHAwTXd/ZLPWrzxNrfhfRtOuZbW4g0zTlNnELdF2t5l08ZURcrGWyw2ruJ7V554b8Rjw2mpywWglvruze1t7kyY+yh+HYLjliuVByMZJ5qXw54oGjabqmk39rJe6VqsaLcwRXHkOGRtyOr7WAIPYqQR26EN6/1/XT8/IX9f18/y8z0+K/0bwtrelX2mrMbnxBZW4W40G2C77iK5CyrHGxTbHLs28Y/3cHFch8SVutLii0i10uaw0trmW6lnWFkgu7pidwjYgB0iB8tSOOGP8VZ58feVfC5sNONs9lYfYdIzcbvsKnO6Q/KN8h3N83ygFs44AB4p8e/8JHoUWnpp32RmlhmupPtHmLI8UAhXYu0bF2gkgluT1AGKl6r5/hf9P8AKxUdH8vxt+u33nHUUUUxBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf/9k=)"
      ],
      "metadata": {
        "id": "ESdObZu1j3vv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a_CIrUEYh6vG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}